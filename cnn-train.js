import * as tf from '@tensorflow/tfjs-node-gpu';
import fs from 'fs/promises';
import path from 'path';
import cliProgress from 'cli-progress';

// --- –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ---
const args = process.argv.slice(2).reduce((acc, cur, i, arr) => {
  if (cur.startsWith('--')) acc[cur.slice(2)] = arr[i + 1];
  return acc;
}, {});

const MODEL_NAME    = args.model ?? path.basename(args.teach ?? 'unnamed-model');
const TEACH_PATH    = args.teach;
const LEARNING_RATE = args.lr ? parseFloat(args.lr) : 0.001;

const DATA_DIR      = './converted-images';
const METRIC_DIR    = './metrics-json';
const MODEL_DIR     = './cnn-models';
const TEMP_DIR      = './cnn-temp';

const EPOCHS        = 30;
const BATCH_SIZE    = 32;
const IMAGE_HEIGHT  = 200;
const IMAGE_WIDTH   = 266;
// –†–∞–Ω–µ–µ –±—ã–ª–æ NUM_CLASSES = 14; —Ç–µ–ø–µ—Ä—å —Ä–µ–≥—Ä–µ—Å—Å–∏—è –æ–¥–Ω–æ–≥–æ –≤—ã—Ö–æ–¥–∞
const NUM_OUTPUTS   = 1;

// –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–≤—ë—Ä—Ç–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞
function convBlock(input, filters, dropRate) {
  let x = tf.layers.conv2d({ filters, kernelSize: 3, padding: 'same', useBias: false }).apply(input);
  x = tf.layers.batchNormalization().apply(x);
  x = tf.layers.leakyReLU({ alpha: 0.1 }).apply(x);
  x = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(x);
  x = tf.layers.dropout({ rate: dropRate }).apply(x);
  return x;
}

// --- –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
function createModel() {
  console.log(`\nüíª –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏: ${MODEL_NAME}`);

  const imgInput = tf.input({ shape: [IMAGE_HEIGHT, IMAGE_WIDTH, 1], name: 'img_input' });
  let x = convBlock(imgInput, 32, 0.1);
  x = convBlock(x, 64, 0.1);
  x = convBlock(x, 128, 0.5);
  x = tf.layers.globalAveragePooling2d({ dataFormat: 'channelsLast' }).apply(x);

  // –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å: —Ä–µ–≥—Ä–µ—Å—Å–∏—è –æ–¥–Ω–æ–≥–æ —á–∏—Å–ª–∞
  const output = tf.layers.dense({ units: NUM_OUTPUTS, activation: 'linear', name: 'output' }).apply(x);

  const model = tf.model({ inputs: imgInput, outputs: output });
  model.compile({
    optimizer: tf.train.adam(LEARNING_RATE),
    loss: 'meanSquaredError',
    metrics: ['mse']
  });

  console.log('üìà Learning rate:', LEARNING_RATE);
  return model;
}

// --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
async function prepareModel() {
  if (TEACH_PATH) {
    console.log(`\nüíæ –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: ${TEACH_PATH}`);
    const modelJson = `file://${path.resolve(TEACH_PATH)}/model.json`;
    const model = await tf.loadLayersModel(modelJson);
    model.compile({ optimizer: tf.train.adam(LEARNING_RATE), loss: 'meanSquaredError', metrics: ['mse'] });
    return model;
  }
  return createModel();
}

// --- –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö ---
async function* dataGen(files) {
  for (const file of files) {
    const imgBuf = await fs.readFile(path.join(DATA_DIR, file));
    const meta = JSON.parse(await fs.readFile(path.join(METRIC_DIR, `${path.basename(file, '.jpg')}.json`), 'utf-8'));
    
    // –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    const imgTensor = tf.node.decodeImage(imgBuf, 1)
      .resizeNearestNeighbor([IMAGE_HEIGHT, IMAGE_WIDTH])
      .toFloat()
      .div(255);

    // –ú–µ—Ç—Ä–∏–∫–∞: —Å—Ä–µ–¥–Ω—è—è –º–µ—Ç—Ä–∏–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤, 0 –∏–Ω–¥–µ–∫—Å
    const labelValue = meta.averageCharMetrics[0];
    const label = tf.scalar(labelValue);

    yield { xs: imgTensor, ys: label };
  }
}

// --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ ---
async function buildDataset() {
  const files = (await fs.readdir(DATA_DIR)).filter(f => f.endsWith('.jpg'));
  const num = files.length;
  const trainSize = Math.floor(num * 0.8);
  const ds = tf.data.generator(() => dataGen(files)).shuffle(num);
  const trainDs = ds.take(trainSize).batch(BATCH_SIZE).prefetch(1);
  const valDs   = ds.skip(trainSize).batch(BATCH_SIZE).prefetch(1);
  return { trainDs, valDs, trainSize };
}

// --- –û–±—É—á–µ–Ω–∏–µ ---
async function train() {
  const model = await prepareModel();
  const { trainDs, valDs, trainSize } = await buildDataset();

  const epochBar = new cliProgress.SingleBar({ format: '–≠–ø–æ—Ö–∞ {value}/{total}', hideCursor: true }, cliProgress.Presets.shades_classic);
  epochBar.start(EPOCHS, 0);
  let batchBar;

  const callbacks = {
    onEpochBegin: epoch => {
      const totalBatches = Math.ceil(trainSize / BATCH_SIZE);
      batchBar = new cliProgress.SingleBar({ format: `–≠–ø–æ—Ö–∞ ${epoch+1} [{bar}] –ë–∞—Ç—á {value}/${totalBatches}`, hideCursor: true }, cliProgress.Presets.shades_classic);
      batchBar.start(totalBatches, 0);
    },
    onBatchEnd: batch => batchBar.update(batch + 1),
    onEpochEnd: async (epoch, logs) => {
      batchBar.stop();
      epochBar.increment();
      console.log(` [–≠–ø–æ—Ö–∞ ${epoch+1} ‚Äî mse=${logs.mse.toFixed(4)}, val_mse=${logs.val_mse.toFixed(4)}]`);
      const out = path.join(TEMP_DIR, MODEL_NAME, `epoch-${epoch+1}`);
      await fs.mkdir(out, { recursive: true });
      await model.save(`file://${out}`);
    }
  };

  await model.fitDataset(trainDs, { epochs: EPOCHS, validationData: valDs, callbacks, verbose: 0 });
  epochBar.stop();

  console.log('\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ');
  const finalPath = path.join(MODEL_DIR, MODEL_NAME);
  await fs.mkdir(finalPath, { recursive: true });
  await model.save(`file://${finalPath}`);
  console.log(`‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ ${finalPath}`);
}

train().catch(e => { console.error('‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:', e); process.exit(1); });
